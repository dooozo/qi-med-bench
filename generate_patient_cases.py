#!/usr/bin/env python3
"""
ç”Ÿæˆæ¯ä¸ªæ‚£è€…çš„å®Œæ•´è¯„æµ‹å®ä¾‹æ–‡ä»¶
æ•´åˆåˆå§‹queryã€å·¥å…·æ•°æ®åº“ã€å‚è€ƒç­”æ¡ˆå’Œè¯„æµ‹æ ‡å‡†
"""

import json
import os
import sys
from openai import OpenAI
import time
from typing import Dict, List, Any

# OpenRouteré…ç½®
API_KEY = "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"
BASE_URL = "https://openrouter.ai/api/v1"
MODEL = "google/gemini-2.5-pro"

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

def call_openrouter_with_retry(messages: List[Dict], max_retries: int = 3, timeout: int = 120) -> str:
    """è°ƒç”¨OpenRouter APIï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model=MODEL,
                messages=messages,
                temperature=0.2,
                timeout=timeout
            )
            return response.choices[0].message.content if response.choices else ""
        except Exception as e:
            print(f"âš ï¸ Attempt {attempt + 1} failed: {str(e)}")
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 5
                print(f"ğŸ”„ Retrying in {wait_time} seconds...")
                time.sleep(wait_time)
            else:
                print(f"âŒ All {max_retries} attempts failed for API call")
                return ""

def load_all_data():
    """åŠ è½½æ‰€æœ‰éœ€è¦çš„æ•°æ®æ–‡ä»¶"""
    print("ğŸ“‚ Loading all data files...")
    
    # 1. åŠ è½½åŸå§‹æ‚£è€…æ•°æ®
    with open('data.json', 'r', encoding='utf-8') as f:
        patients_data = json.load(f)
    
    # 2. åŠ è½½evalæ•°æ®é›†ï¼ˆåŒ…å«å‚è€ƒç­”æ¡ˆå’Œè¯„æµ‹æ ‡å‡†ï¼‰
    with open('eval_dataset.json', 'r', encoding='utf-8') as f:
        eval_data = json.load(f)
    
    # 3. åŠ è½½åˆå§‹queriesï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    initial_queries = {}
    if os.path.exists('initial_queries.json'):
        with open('initial_queries.json', 'r', encoding='utf-8') as f:
            queries_list = json.load(f)
            for query in queries_list:
                initial_queries[query['patient_id']] = query
    
    # 4. åŠ è½½å·¥å…·å®šä¹‰
    with open('qi_med_tools.json', 'r', encoding='utf-8') as f:
        tools_data = json.load(f)
    
    # 5. åŠ è½½åŒ»ç–—æ•°æ®åº“
    databases = {}
    db_dir = "medical_databases"
    if os.path.exists(db_dir):
        index_file = os.path.join(db_dir, "database_index.json")
        if os.path.exists(index_file):
            with open(index_file, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
            
            for db_file in index_data.get('database_files', []):
                db_path = os.path.join(db_dir, db_file)
                if os.path.exists(db_path):
                    tool_id = db_file.split('_')[0]
                    with open(db_path, 'r', encoding='utf-8') as f:
                        databases[tool_id] = json.load(f)
    
    print(f"âœ… Loaded {len(patients_data)} patients, {len(eval_data)} eval entries")
    print(f"   {len(initial_queries)} initial queries, {len(databases)} tool databases")
    
    return patients_data, eval_data, initial_queries, tools_data, databases

def generate_evaluation_rubrics(patient_data: Dict, eval_item: Dict) -> List[Dict]:
    """åŸºäºæ‚£è€…æ•°æ®å’Œå‚è€ƒç­”æ¡ˆç”Ÿæˆè¯„æµ‹æ ‡å‡†"""
    
    prompt = f"""
ä½ æ˜¯ä¸€ä½åŒ»å­¦è¯„æµ‹ä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆè¯¦ç»†çš„è¯„æµ‹æ ‡å‡†ï¼ˆrubricsï¼‰ã€‚

æ‚£è€…ä¿¡æ¯ï¼š
- ID: {patient_data['id']}
- è¯Šæ–­: {patient_data['diagnosis']}
- æ²»ç–—æ ‡ç­¾: {patient_data['label']}

å‚è€ƒç­”æ¡ˆï¼š
{eval_item.get('reference_answer', patient_data['result'])}

ç°æœ‰è¯„æµ‹æ ‡å‡†ï¼š
{json.dumps(eval_item.get('rubrics', []), ensure_ascii=False, indent=2)}

è¦æ±‚ç”Ÿæˆ3-5ä¸ªå…·ä½“çš„è¯„æµ‹æ ‡å‡†ï¼Œæ¯ä¸ªæ ‡å‡†åŒ…å«ï¼š
1. criterion: è¯„æµ‹ç‚¹åç§°
2. description: è¯¦ç»†æè¿°
3. weight: æƒé‡(0.1-0.4ä¹‹é—´)

ç¡®ä¿æƒé‡æ€»å’Œä¸º1.0ï¼Œæ ‡å‡†åº”æ¶µç›–ï¼š
- è¯Šæ–­å‡†ç¡®æ€§
- æ²»ç–—æ–¹æ¡ˆåˆç†æ€§  
- å·¥å…·è°ƒç”¨å®Œæ•´æ€§
- ä¸´åºŠå†³ç­–é€»è¾‘

ç›´æ¥è¿”å›JSONæ ¼å¼çš„åˆ—è¡¨ï¼š
"""

    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»å­¦è¯„æµ‹ä¸“å®¶ï¼Œæ“…é•¿åˆ¶å®šå®¢è§‚ã€å…¨é¢çš„è¯„æµ‹æ ‡å‡†ã€‚"},
        {"role": "user", "content": prompt}
    ]
    
    response = call_openrouter_with_retry(messages, timeout=60)
    
    try:
        rubrics = json.loads(response)
        # éªŒè¯æƒé‡æ€»å’Œ
        total_weight = sum(r.get('weight', 0) for r in rubrics)
        if abs(total_weight - 1.0) > 0.1:
            # å½’ä¸€åŒ–æƒé‡
            for r in rubrics:
                r['weight'] = r.get('weight', 0) / total_weight if total_weight > 0 else 1.0/len(rubrics)
        return rubrics
    except json.JSONDecodeError:
        # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ‡å‡†
        return [
            {"criterion": "è¯Šæ–­å‡†ç¡®æ€§", "description": "è¯Šæ–­æ˜¯å¦å‡†ç¡®", "weight": 0.3},
            {"criterion": "æ²»ç–—æ–¹æ¡ˆåˆç†æ€§", "description": "æ²»ç–—æ–¹æ¡ˆæ˜¯å¦åˆç†", "weight": 0.3},
            {"criterion": "å·¥å…·è°ƒç”¨å®Œæ•´æ€§", "description": "æ˜¯å¦å……åˆ†åˆ©ç”¨å·¥å…·è·å–ä¿¡æ¯", "weight": 0.2},
            {"criterion": "ä¸´åºŠå†³ç­–é€»è¾‘", "description": "å†³ç­–è¿‡ç¨‹æ˜¯å¦é€»è¾‘æ¸…æ™°", "weight": 0.2}
        ]

def create_patient_case(patient_data: Dict, eval_item: Dict, initial_query: Dict, 
                       tools_data: Dict, databases: Dict) -> Dict:
    """ä¸ºå•ä¸ªæ‚£è€…åˆ›å»ºå®Œæ•´çš„è¯„æµ‹å®ä¾‹"""
    
    patient_id = str(patient_data['id'])
    print(f"ğŸ“‹ Creating case for patient {patient_id}")
    
    # 1. è·å–åˆå§‹query
    if initial_query:
        initial_query_text = initial_query['initial_query']
    else:
        # å¦‚æœæ²¡æœ‰ç”Ÿæˆçš„åˆå§‹queryï¼Œä»evalæ•°æ®é›†ä¸­æå–æˆ–ä½¿ç”¨åŸºæœ¬ä¿¡æ¯
        initial_query_text = f"æ‚£è€…{patient_data['gender']}ï¼Œ{patient_data['age']}å²ï¼Œè¯·é—®è¿™ä½æ‚£è€…çš„è¯Šç–—æ–¹æ¡ˆåº”è¯¥æ˜¯ä»€ä¹ˆï¼Ÿ"
    
    # 2. æ„å»ºå·¥å…·è°ƒç”¨ç»“æœæ˜ å°„
    tool_call_results_map = {}
    for tool in tools_data['tools']:
        tool_id = tool['tool_id']
        if tool_id in databases and patient_id in databases[tool_id]:
            tool_call_results_map[tool_id] = databases[tool_id][patient_id]
        else:
            # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œç”Ÿæˆç©ºç»“æœ
            tool_call_results_map[tool_id] = {"status": "no_data_available"}
    
    # 3. ç”Ÿæˆè¯„æµ‹æ ‡å‡†
    evaluation_rubrics = generate_evaluation_rubrics(patient_data, eval_item)
    
    # 4. æ„å»ºå®Œæ•´çš„æ‚£è€…æ¡ˆä¾‹
    patient_case = {
        "patient_id": patient_id,
        "initial_query": initial_query_text,
        "tool_call_results_map": tool_call_results_map,
        "reference_conclusion": eval_item.get('reference_answer', patient_data['result']),
        "evaluation_rubrics": evaluation_rubrics,
        "metadata": {
            "gender": patient_data['gender'],
            "age": patient_data['age'],
            "diagnosis": patient_data['diagnosis'],
            "category": eval_item.get('category', patient_data['label']),
            "original_summary": patient_data['summary'],
            "generated_at": time.strftime("%Y-%m-%d %H:%M:%S")
        }
    }
    
    return patient_case

def generate_all_patient_cases():
    """ç”Ÿæˆæ‰€æœ‰æ‚£è€…çš„è¯„æµ‹å®ä¾‹"""
    print("ğŸš€ Starting Patient Cases Generation")
    print("=" * 50)
    
    # åŠ è½½æ‰€æœ‰æ•°æ®
    patients_data, eval_data, initial_queries, tools_data, databases = load_all_data()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    cases_dir = "patient_cases"
    if not os.path.exists(cases_dir):
        os.makedirs(cases_dir)
    
    # åˆ›å»ºevalæ•°æ®çš„æ˜ å°„ï¼ˆæŒ‰IDï¼‰
    eval_map = {}
    for item in eval_data:
        eval_map[str(item['id'])] = item
    
    # ç”Ÿæˆæ¯ä¸ªæ‚£è€…çš„æ¡ˆä¾‹
    all_cases = []
    failed_cases = []
    
    for i, patient in enumerate(patients_data):
        patient_id = str(patient['id'])
        print(f"\nğŸ“‹ Processing patient {patient_id} ({i+1}/{len(patients_data)})")
        
        try:
            # è·å–å¯¹åº”çš„evalæ•°æ®
            eval_item = eval_map.get(patient_id, {})
            
            # è·å–åˆå§‹query
            initial_query = initial_queries.get(patient_id, {})
            
            # åˆ›å»ºæ‚£è€…æ¡ˆä¾‹
            patient_case = create_patient_case(
                patient, eval_item, initial_query, tools_data, databases
            )
            
            # ä¿å­˜å•ä¸ªæ¡ˆä¾‹æ–‡ä»¶
            case_file = os.path.join(cases_dir, f"patient_{patient_id}.json")
            with open(case_file, 'w', encoding='utf-8') as f:
                json.dump(patient_case, f, ensure_ascii=False, indent=2)
            
            all_cases.append(patient_case)
            print(f"âœ… Generated case for patient {patient_id}")
            
            # é¿å…APIé™é€Ÿ
            time.sleep(1)
            
        except Exception as e:
            print(f"âŒ Failed to generate case for patient {patient_id}: {e}")
            failed_cases.append(patient_id)
    
    # ä¿å­˜æ‰€æœ‰æ¡ˆä¾‹çš„æ±‡æ€»æ–‡ä»¶
    summary_file = "all_patient_cases.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(all_cases, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜æ¡ˆä¾‹ç´¢å¼•
    index_data = {
        "total_cases": len(all_cases),
        "failed_cases": failed_cases,
        "cases_directory": cases_dir,
        "individual_files": [f"patient_{case['patient_id']}.json" for case in all_cases],
        "generated_at": time.strftime("%Y-%m-%d %H:%M:%S")
    }
    
    with open("patient_cases_index.json", 'w', encoding='utf-8') as f:
        json.dump(index_data, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 50)
    print("ğŸ‰ Patient Cases Generation Completed!")
    print(f"ğŸ“Š Successfully generated {len(all_cases)} patient cases")
    print(f"âŒ Failed cases: {len(failed_cases)}")
    print(f"ğŸ“ Individual cases saved in: {cases_dir}/")
    print(f"ğŸ“ Summary file: {summary_file}")
    print(f"ğŸ“ Index file: patient_cases_index.json")

def main():
    """ä¸»å‡½æ•°"""
    try:
        generate_all_patient_cases()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Generation interrupted by user")
    except Exception as e:
        print(f"\nâŒ Error during generation: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()