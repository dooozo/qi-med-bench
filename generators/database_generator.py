"""
åŒ»ç–—æ•°æ®åº“ç”Ÿæˆå™¨ - é‡æ„ç‰ˆæœ¬
"""

import json
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Any, Tuple
from tqdm import tqdm

from core.base import BaseGenerator
from core.data_manager import DataManager
from config import Config

class DatabaseGenerator(BaseGenerator):
    """åŒ»ç–—æ•°æ®åº“ç”Ÿæˆå™¨"""
    
    def __init__(self, config: Config):
        super().__init__(config)
        self.data_manager = DataManager(config)
    
    def generate_tool_data(self, patient: Dict[str, Any], tool: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸ºå•ä¸ªæ‚£è€…å’Œå·¥å…·ç”Ÿæˆæ•°æ®"""
        patient_info = f"æ‚£è€…{patient['id']}ï¼š{patient['gender']}, {patient['age']}å², è¯Šæ–­ï¼š{patient['diagnosis']}"
        
        prompt = f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„åŒ»å­¦æ•°æ®å·¥ç¨‹å¸ˆã€‚è¯·åŸºäºä»¥ä¸‹æ‚£è€…ä¿¡æ¯ï¼Œä¸ºå·¥å…·"{tool['tool_name']}"ç”Ÿæˆç¬¦åˆå…¶output_schemaçš„çœŸå®ã€åˆç†çš„åŒ»ç–—æ•°æ®ã€‚

æ‚£è€…ä¿¡æ¯ï¼š
{patient_info}

ç—…ä¾‹æ‘˜è¦ï¼š
{patient['summary']}

å·¥å…·å®šä¹‰ï¼š
- å·¥å…·åç§°ï¼š{tool['tool_name']}
- å·¥å…·æè¿°ï¼š{tool['tool_description']}
- è¾“å‡ºæ ¼å¼ï¼š{json.dumps(tool['output_schema'], ensure_ascii=False, indent=2)}

è¦æ±‚ï¼š
1. ç”Ÿæˆçš„æ•°æ®å¿…é¡»ä¸¥æ ¼ç¬¦åˆoutput_schemaçš„æ ¼å¼
2. æ•°å€¼åº”è¯¥åœ¨åŒ»å­¦ä¸Šåˆç†ï¼ˆä¾‹å¦‚ï¼šè‚¿ç˜¤å¤§å°ã€å®éªŒå®¤æŒ‡æ ‡ç­‰ï¼‰
3. å¦‚æœæ‚£è€…æ‘˜è¦ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·åŸºäºå…¶è¯Šæ–­ã€å¹´é¾„ã€æ€§åˆ«ç­‰æ¨æµ‹åˆç†æ•°å€¼
4. å¯¹äºè‚ºç™Œä¸‰æœŸæ‚£è€…ï¼Œæ•°æ®åº”è¯¥ä½“ç°å…¸å‹çš„ç–¾ç—…ç‰¹å¾
5. ç›´æ¥è¿”å›JSONæ ¼å¼çš„æ•°æ®ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Š

è¯·ç”Ÿæˆæ•°æ®ï¼š
"""
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»å­¦æ•°æ®å·¥ç¨‹å¸ˆï¼Œæ“…é•¿åŸºäºæ‚£è€…ä¿¡æ¯ç”Ÿæˆç¬¦åˆåŒ»å­¦æ ‡å‡†çš„ç»“æ„åŒ–æ•°æ®ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        response = self.api_client.call_api(messages)
        return self.parse_json_response(response, f"Patient {patient['id']}, Tool {tool['tool_id']}")
    
    def process_patient_tool_pair(self, args: Tuple[Dict, Dict]) -> Tuple[str, str, Dict, bool]:
        """å¤„ç†å•ä¸ªæ‚£è€…-å·¥å…·å¯¹"""
        patient, tool = args
        
        try:
            result = self.generate_tool_data(patient, tool)
            self.update_stats(processed=1)
            return (patient['id'], tool['tool_id'], result, True)
            
        except Exception as e:
            self.logger.error(f"å¤„ç†å¤±è´¥ - Patient {patient['id']}, Tool {tool['tool_id']}: {e}")
            self.update_stats(failed=1)
            return (patient['id'], tool['tool_id'], {}, False)
    
    def generate_databases_parallel(self, patients_data: List[Dict], tools: List[Dict]) -> Dict[str, Dict]:
        """å¹¶è¡Œç”Ÿæˆæ‰€æœ‰æ•°æ®åº“"""
        self.logger.info(f"ğŸš€ å¯åŠ¨å¤šçº¿ç¨‹ç”Ÿæˆ - {self.config.max_workers} çº¿ç¨‹")
        
        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
        tasks = [(patient, tool) for patient in patients_data for tool in tools]
        total_tasks = len(tasks)
        
        self.logger.info(f"ğŸ“Š æ€»ä»»åŠ¡æ•°: {total_tasks} ({len(patients_data)} æ‚£è€… Ã— {len(tools)} å·¥å…·)")
        
        # åˆå§‹åŒ–æ•°æ®åº“ç»“æ„
        databases = {tool['tool_id']: {} for tool in tools}
        
        # æ‰§è¡Œå¹¶è¡Œä»»åŠ¡
        with ThreadPoolExecutor(max_workers=self.config.max_workers) as executor:
            with tqdm(total=total_tasks, desc="ç”ŸæˆåŒ»ç–—æ•°æ®") as pbar:
                
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_task = {
                    executor.submit(self.process_patient_tool_pair, task): task 
                    for task in tasks
                }
                
                # å¤„ç†å®Œæˆçš„ä»»åŠ¡
                for future in as_completed(future_to_task):
                    patient_id, tool_id, result, success = future.result()
                    
                    if success:
                        databases[tool_id][str(patient_id)] = result
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    pbar.update(1)
                    stats = self.get_stats()
                    pbar.set_postfix({
                        'æˆåŠŸ': stats['total_processed'],
                        'å¤±è´¥': stats['total_failed'], 
                        'é€Ÿç‡': f"{stats['requests_per_second']:.1f}/s"
                    })
        
        return databases
    
    def save_databases(self, databases: Dict, tools: List[Dict], patients: List[Dict]) -> None:
        """ä¿å­˜æ•°æ®åº“æ–‡ä»¶"""
        self.logger.info("ğŸ’¾ ä¿å­˜æ•°æ®åº“æ–‡ä»¶...")
        
        # ä¿å­˜å„å·¥å…·æ•°æ®åº“
        for tool in tools:
            tool_id = tool['tool_id']
            tool_name = tool['tool_name']
            
            db_file = self.config.get_db_file(tool_id, tool_name)
            self.save_json(databases[tool_id], str(db_file))
            
            self.logger.info(f"âœ… ä¿å­˜ {tool_id} æ•°æ®åº“: {len(databases[tool_id])} æ¡è®°å½•")
        
        # ä¿å­˜ç´¢å¼•æ–‡ä»¶
        stats = self.get_stats()
        self.data_manager.save_database_index(tools, patients, stats)
    
    def generate(self) -> Dict[str, Dict]:
        """ä¸»ç”Ÿæˆæ–¹æ³•"""
        # åŠ è½½æ•°æ®
        patients_data, _, _, tools_data = self.data_manager.load_all_data()
        
        # å¹¶è¡Œç”Ÿæˆæ•°æ®åº“
        databases = self.generate_databases_parallel(patients_data, tools_data)
        
        # ä¿å­˜æ•°æ®åº“
        self.save_databases(databases, tools_data, patients_data)
        
        return databases